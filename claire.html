<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Claire Campbell — LAIDS</title>
  <link rel="stylesheet" href="assets/member.css" />
</head>
<body>
  <!-- Hero banner with image + mauve glass pill nav -->
  <header class="hero hero--short">
    <!-- Top-left pills (homepage + peers) -->
    <nav class="hero-topline">
      <a class="pill mauve" href="index.html">← Homepage</a>
      <a class="pill light" href="christopher.html">Christopher Blignaut's work</a>
      <a class="pill light" href="sian.html">Sian Caine's work</a>
    </nav>
  
    <div class="container hero-grid">
      <!-- LEFT: text -->
      <div class="hero-copy">
        <h1 class="title">Claire Campbell</h1>
        <p class="subtitle">CMPCLA004</p>
  
        <!-- primary actions (white-glow pills) -->
        <div class="actions">
          <a class="button glass" href="#resources">Jump to resources</a>
          <a class="button glass" href="#results">See results</a>
        </div>
      </div>
  
      <!-- RIGHT: picture -->
      <figure class="hero-art">
        <img src="images/claire_profile.jpg" alt="Claire Campbell">
      </figure>
    </div>
  </header>

  <main>

    <!-- Abstract -->
    <section id="abstract" class="section">
      <div class="container">
        <article class="card">
          <p class="eyebrow">Summary</p>
          <h2 class="display">Final Paper Overview</h2>
          <p class="prose">
            My work focused on designing, quantising, and evaluating two compact intrusion-detection models for constrained devices. 
            The goal was to see if they could equal or outperform the baseline Convolutional Neural Network (CNN) model in terms of 
            performance and resource consumption, and to assess their ability to detect previously unseen attacks.
          </p>
          <p class="prose">
            <em>Note: </em> Convolutional Neural Network (CNN), Convolutional Neural Network Long Short-Term Memory (CNN-LSTM), Deep Belief Network (DBN).
          </p>
          <ul class="checklist light">
            <li><strong>Problem.</strong> Many devices are constrained on compute, memory, and energy, limiting deployment of conventional AI-based intrusion detection.</li>
            <li><strong>Aim.</strong> Test whether lightweight deep models meet device constraints without compromising detection, and assess how post-training quantisation affects that trade-off.</li>
            <li><strong>Models.</strong> Baseline CNN, hybrid CNN–LSTM, and Deep Belief Network (DBN).</li>
            <li><strong>Data & setup.</strong> CICIDS2017 used for training and evaluation.</li>
            <li><strong>Metrics.</strong> Detection (Accuracy, F1) and compute efficiency (latency, throughput, memory footprint).</li>
            <li><strong>Quantisation schemes.</strong> Float16, INT8 Dynamic (weights-only), and full INT8.</li>
          </ul>
        </article>
        
      </div>
    </section>

    <!-- Model designs -->
    <section id="models" class="section">
      <div class="container">
        <h2 class="section-heading">Model Designs</h2>

        <!-- CNN -->
        <figure class="card model-card reverse">
          <h3>Baseline CNN</h3>
          <div class="model-body">
            <img class="model-img" src="images/CNN_arch.png" alt="CNN architecture">
            <figcaption class="model-notes">
              <ul class="clean">
                <li>Two convolutional blocks with batch normalisation and pooling to learn local patterns and progressively reduce features.</li>
                <li>Global Average Pooling minimises overfitting.</li>
                <li>Compact dense head (with optional dropout) maps the pooled features to class logits.</li>
                <li>Softmax layer outputs the final multiclass probabilities.</li>
              </ul>
            </figcaption>
          </div>
        </figure>

        <!-- CNN-LSTM -->
        <figure class="card model-card reverse">
          <h3>CNN-LSTM</h3>
          <div class="model-body">
            <img class="model-img" src="images/CNN-LSTM_arch.png" alt="CNN-LSTM architecture">
            <figcaption class="model-notes">
              <ul class="clean">
                <li>Two TimeDistributed convolutional blocks with pooling and batch normalisation learn local patterns at each timestep.</li>
                <li>LSTM layer captures temporal dynamics across the window. </li>
                <li>Dense head with dropout provides class logits.</li>
                <li>Softmax layer produces the final multiclass output.</li>
              </ul>
            </figcaption>
          </div>
        </figure>

        <!-- DBN -->
        <figure class="card model-card reverse">
          <h3>DBN Architecture</h3>
          <div class="model-body">
            <img class="model-img" src="images/DBN_arch.png" alt="DBN architecture">
            <figcaption class="model-notes">
              <ul class="clean">
                <li>Unsupervised pretraining with stacked Restricted Boltzmann Machines (RBMs) followed by supervised fine-tuning.</li>
                <li>Supervised head: ReLU → Dropout → Dense → Softmax.</li>
                <li>Pretraining learns useful structure without labels, and the supervised head adapts those features to the multiclass classification.</li>
              </ul>
            </figcaption>
          </div>
        </figure>    
      </div>
    </section>
    
    <!-- Experimentation: 3 tiles -->
    <section id="experiments" class="section">
      <div class="container">
        <h2 class="section-heading">Experimentation Overview</h2>
        <div class="exp-tiles">
          <div class="exp-tile">
            <h4>Benchmarking</h4>
            <p style="text-align: justify">
              This experiment establishes a performance baseline by evaluating the full-precision 
              (Float32) CNN–LSTM and DBN under the same protocol as the baseline CNN. 
              Benchmarking enables a fair comparison across architectures and shows how well each model performs 
              and how much computing resources it uses. It also provides the reference point for later 
              checks on whether quantised versions maintain comparable performance 
              while improving efficiency.
            </p>
          </div>
          <div class="exp-tile">
            <h4>Quantisation</h4>
            <p style="text-align: justify;">
              This experiment examines how post-training quantisation affects both accuracy and efficiency. 
              Quantised variants include Float16, INT8 Dynamic, and full INT8 (where supported). These are produced for the CNN, 
              CNN–LSTM, and DBN and compared against their Float32 counterparts. 
              The analysis tests whether smaller, faster models can deliver 
              similar detection quality with lower latency, higher throughput, and reduced memory.
            </p>
          </div>
          <div class="exp-tile">
            <h4>Generalisation</h4>
            <p style="text-align: justify;">
              This experiment assesses the ability of the models and their quantised variants to handle unseen ("zero-day”) attacks. 
              The setup simulates realistic scenarios by withholding entire attack families during training and evaluating detection 
              on traffic that includes those previously unseen threats. This ensures the models learn 
              general patterns of malicious behaviour rather than memorising known signatures. A further 2D CNN model variant was added to this 
              experiment. 
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- Results -->
    <section id="results" class="section">
      <div class="container">
        <h2 class="section-heading">Results</h2>
        <div class="results-stack">
          <!-- Benchmarking -->
          <article class="card result-panel">
            <header class="result-head">
              <p class="eyebrow">Benchmarking</p>
              <h3 class="display">Multiclassification performance</h3>
            </header>
            <div class="result-body">
              <figure class="result-media">
                <img src="images/benchmark_claire.png"
                    alt="Multiclassification performance of models">
                <figcaption>Multiclassification performance of models.</figcaption>
              </figure>
              <div class="result-notes">
                <ul class="clean">
                  <li><strong>CNN-LSTM</strong>: strongest overall. Achieving a high accuracy, lower false alarms, and most stable across classes.</li>
                  <li><strong>1D CNN</strong>: very sensitive. Achieving a high attack recall but a lot of Normal traffic misclassified as attacks.</li>
                  <li><strong>DBN</strong>: strong detection on major classes but higher false-alarm rate.</li>
                </ul>
                <p class="muted-key">Takeaway: CNN-LSTM is the most reliable, while CNN/DBN need better Normal filtering.</p>
              </div>
            </div>
          </article>
      
          <!-- Quantisation (flip layout) -->
          <article class="card result-panel reverse">
            <header class="result-head">
              <p class="eyebrow">Quantisation</p>
              <h3 class="display">Latency & storage vs precision</h3>
            </header>
            <div class="result-body">
              <figure class="result-media">
                <img src="images/Storage vs Precision.png"
                    alt="Storage vs precision normalised to Float32 = 1.0 for each model and quantisation scheme">
                <figcaption>Normalised storage across Float32, Float16, INT8 Dynamic, INT8 Full.</figcaption>
              </figure>
              <div class="result-notes">
                <ul class="clean">
                  <li><strong>Float16 & INT8 Dynamic</strong> keep <em>CNN-LSTM</em> near-lossless; INT8 Dynamic, however, is faster.</li>
                  <li><strong>DBN</strong> accuracy remains steady for Float32, Float16, and INT8 Dynamic. 
                    Latency rises which is likely due to quant overheads on small layers.</li>
                  <li><strong>CNN</strong> INT8 Dynamic lowers false negatives but increases false alarms.</li>
                  <li><strong>INT8 Full</strong> causes the CNN to fail, a slight decline in the CNN-LSTM's detection, and is not supported for DBN in this stack.</li>
                </ul>
                <p class="muted-key">Takeaway: <strong>INT8 Dynamic</strong> is a strong candidate for lightweight deployment.</p>
              </div>
            </div>
          </article>

          <!-- Generalisation -->
          <article class="card result-panel">
            <header class="result-head">
              <p class="eyebrow">Generalisation</p>
              <h3 class="display">Zero-day detection</h3>
            </header>
            <div class="result-body">
              <figure class="result-media">
                <img src="images/Percentage Unseen Predicted as Malicious .png"
                    alt="Zero-day generalisation comparison across models">
                <figcaption>Unseen DoS and Bots detection.</figcaption>
              </figure>
              <div class="result-notes">
                <ul class="clean">
                  <li><strong>1D CNN</strong>: strong on Bots (~91%), weaker on DoS (~68%).</li>
                  <li><strong>CNN-LSTM</strong>: less sensitive to detecting DoS and Bot attacks.</li>
                  <li><strong>DBN</strong>: relatively better at detecting DoS than Bot attacks.</li>
                  <li><strong>2D CNN (exploratory)</strong>: best unknown detection likely due to cross-feature filters.</li>
                </ul>
                <p class="muted-key">Takeaway: Unknown detection depends on both the model and the selected false positive rate threshold.</p>
              </div>
            </div>
          </article>
      </div>
    
        
    
      </div>
    </section>

    <!-- Conclusion -->
    <section id="conclusion" class="section">
      <div class="container">
        <article class="card">
          <p class="eyebrow">Key Takeaways</p>
          <h2 class="display">Conclusion</h2>

          <ul class="checklist light">
            <li><strong>Best overall.</strong> Across full-precision and quantised variants, the <strong>CNN–LSTM</strong> offered the 
              most reliable balance of detection quality, latency, and size. This was especially under <strong>Float16</strong> and 
              <strong>INT8 Dynamic</strong>, which preserved accuracy while shrinking and speeding up the model.</li>

            <li><strong>Quantisation policy.</strong> <strong>INT8 Dynamic</strong> is a strong default across models. 
              <strong>Float16</strong> also allowed for size reduction with stable accuracy. 
              <strong>Full INT8</strong> degraded performance in this stack and would likely require 
              <em>quantisation-aware training (QAT)</em> to be dependable.</li>

            <li><strong>Zero-day generalisation.</strong> Sensitivity to unseen attacks depended strongly on the 
              chosen <strong>false-positive rate (FPR)</strong>. The exploratory <strong>2D CNN</strong> improved 
              unknown-attack detection, suggesting value in architectures that capture cross-feature structure.</li>

            <li><strong>Deployment guidance.</strong> For edge devices, deploy <strong>CNN–LSTM (INT8 Dynamic)</strong> 
              and tune the decision threshold to the application’s FPR budget. Monitor both false positives and false negatives 
              in production and recalibrate as traffic shifts.</li>

              <li><strong>Overall.</strong> Lightweight AI-IDS is feasible and 2D CNN variants are promising for boosting 
                unknown-attack detection.</li>

            <li><strong>Future work.</strong> A 2D CNN-LSTM capable of unknown detected can be explored with 
              <strong>Quantisation-aware training</strong> to allow for a full INT8 variant. 
              The models can also be validated on-device with real traffic to improve latency/throughput targets.</li>
          </ul>
        </article>
      </div>
    </section>

    <!-- Resources (Docs) -->
    <section id="resources" class="section">
      <div class="container">
        <h2 class="section-heading">Resources</h2>
    
        <div class="doc-grid">
          <!-- Literature Review -->
          <article class="doc-card">
            <h3>Literature Review</h3>
            <iframe class="doc-preview" src="docs/Literature_Review_Claire_Campbell.pdf#toolbar=0" title="Literature Review"></iframe>
    
            <details class="doc-abs">
              <summary>Read abstract</summary>
              <p style="text-align: justify">
                The rapid increase of Internet of Things (IoT) devices and wireless sensor networks (WSNs) has introduced significant cybersecurity
                challenges, particularly for resource-constrained networks. Traditional Intrusion Detection Systems (IDSs) are struggling to keep
                up with evolving cybersecurity threats, and AI-driven IDS models, while more adaptable and accurate, are resource-intensive and
                unsuitable for constrained environments. This literature review reveals that Lightweight AI-IDS (LAIDS) offer a promising solution
                by balancing security effectiveness with computational efficiency. By analysing existing research on lightweight models, the review
                demonstrates the potential of hybrid approaches that combine machine learning (ML) and deep learning (DL) techniques to enhance
                detection while minimising computational costs. The findings emphasise the need for scalable, efficient, and adaptive IDS solutions
                tailored to low-power environments, enabling real-time cybersecurity for IoT and other resource-constrained networks.
              </p>
            </details>
    
            <div class="doc-actions">
              <a class="button secondary" href="docs/Literature_Review_Claire_Campbell.pdf">Open PDF</a>
            </div>
          </article>
    
          <!-- Final Paper -->
          <article class="doc-card">
            <h3>Final Paper</h3>
            <iframe class="doc-preview" src="docs/Final_Paper_Claire_Campbell.pdf#toolbar=0" title="Final Paper"></iframe>
    
            <details class="doc-abs">
              <summary>Read abstract</summary>
              <p style="text-align: justify">
                Many Internet of Things (IoT) based edge devices remain constrained in compute, memory and energy and thus, their deployment 
                of conventional, resource-intensive Artificial Intelligence (AI) based Intrusion Detection Systems is limited. This study 
                investigates whether lightweight deep models can meet device constraints without sacrificing detection, and how post-training 
                quantisation affects that trade-off. A Baseline Convolution Neural Network (CNN), a hybrid CNN-Long Short Term Memory 
                (CNN-LSTM), and a Deep Belief Network (DBN) are evaluated on CICIDS2017 under edge-realistic conditions (batch size=1), 
                reporting accuracy and F1 alongside latency, throughput, and memory footprint. Three post-training precisions, Float16, 
                INT8 Dynamic (weight-only), and full INT8, are applied and zero-day generalisation is assessed by holding out one attack 
                class and operating at a fixed false-positive rate (FPR) on Normal Traffic. Results demonstrate that Float16 presents
                as a safe, overall quantisation default. INT8 Dynamic achieves the largest reductions and, CNN-LSTM, improves speed with no 
                accuracy loss, thus making it the most-balanced candidate. While INT8 degrades performance and requires Quantisation-Aware 
                Training. Generalisation was strongly dependent on the false-positive rate selected. At FPR= 30(Bots), the CNN is most 
                sensitive and at FPR= 0.15(DoS), the DBN is most sensitive. Overall, the CNN-LSTM INT8 Dynamic offers 
                a strong balance between accuracy, latency, and size.

              </p>
            </details>
    
            <div class="doc-actions">
              <a class="button secondary" href="docs/Final_Paper_Claire_Campbell.pdf">Open PDF</a>
            </div>
          </article>
        </div>
      </div>
    </section>
  
  </main>

  <footer class="site-footer">
    <div class="container footer-grid">
      <div class="footer-brand">
        <img src="images/UCT.png" alt="UCT logo">
        <div>
          <strong>University of Cape Town</strong><br>
          School of IT · Department of Computer Science
        </div>
      </div>
  
      <div class="footer-meta">
        <div>Tel: <a href="tel:+27216502663">+27 21 650 2663</a></div>
        <div>Email: <a href="mailto:dept@cs.uct.ac.za">dept@cs.uct.ac.za</a></div>
        <div>Website: <a href="https://sit.uct.ac.za">sit.uct.ac.za</a></div>
        <div class="footer-copy">© 2025 University of Cape Town — School of IT · LAIDS</div>
      </div>
    </div>
  </footer>
</body>
